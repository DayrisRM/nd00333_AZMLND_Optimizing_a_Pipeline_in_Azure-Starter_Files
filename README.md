# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
This dataset contains information about the bank's customers. We want to know if the client receives a fixed-term deposit or not.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model was a MaxAbsScaler LightGBM  with accuracy 0.9151 in AutoML.


## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

**What are the benefits of the parameter sampler you chose?**

**What are the benefits of the early stopping policy you chose?**
**********************************************************************
To develop this project I modified udacity-project and train.py.
In the train.py I obtained the data and cleaned with the cleand_data function.
After that I splitted the data into train and test sets.
In the main function I received the parameters for use the Logistic regression algorithm.

For training I used the RandomParameterSampling and configured the values required by main method in train.py
In this case they are discrete hyperparameters, it will take a value of those specified for each parameter.

I choosed a BanditPolicy. It is a termination policy based on the delay factor or the amount of delay and the evaluation interval.
This directive terminates those series where the main metric is not within the specified delay factor or amount with respect to
to the best performing series.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
**********************************************************************
For AutoML I obtained the data and prepared it to pass it on to the experiment.
It was a classification experiment with Accuracy as the main metric.

In some algorithms executed by the experiment the result was quite similar, for example between LightGBM and XGBoostClassifier. The accuracy of these two algorithms was very similar.
The results obtained by AutoML are better. One of the main advantages is that it allows you to see the accuracy for different algorithms with few lines of code.

One of the improvements I would make would be to preprocess the data better and see if it returns better results.
